{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "#from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "from torchvision import models, transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######################## configure device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # 1 is another GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "\n",
    "################## Set random seem for reproducibility\n",
    "manualSeed = 9432\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "plt.ion()   # interactive mode\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Steps for training a Neural Network are:\n",
    "\n",
    "1. Load Data by creating a dataloader\n",
    "2. Define the Network Model\n",
    "3. Training the Network\n",
    "4. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load Data : Dataloaders\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformations to be used for Data Augmentagtion, \n",
    "apply_transform = transforms.Compose([transforms.Resize(32),transforms.ToTensor()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset\n",
    "\n",
    "class MNIST_train(Dataset):\n",
    "    # customized dataset\n",
    "    def __init__(self, img_path, csv_name, transforms):\n",
    "        \n",
    "       \n",
    "        \n",
    "        img_nm=[]\n",
    "        lbl=[]\n",
    "        # read the entire csv file and save image_name, lbls\n",
    "        with open(csv_name) as csv_file:\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            for row in csv_reader:\n",
    "                img_nm.append(row[0])\n",
    "                lbl.append(int(float(row[1])))\n",
    "                \n",
    "               \n",
    "        \n",
    "        self.img_nm=img_nm\n",
    "        self.lbl=lbl\n",
    "        self.img_path=img_path # dir of images.\n",
    "        self.transform=transforms\n",
    "        \n",
    "      \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        ############# Return the sample data,gt for the input index\n",
    "        # read the input image, gt\n",
    "        # Read image as PIL\n",
    "        tmp_img = Image.open(self.img_path+self.img_nm[index])\n",
    "        # apply transform\n",
    "        if self.transform is not None:\n",
    "            tmp_img = self.transform(tmp_img)\n",
    "        \n",
    "        # convert label to tensor\n",
    "        tmp_lbl=self.lbl[index]\n",
    "        \n",
    "        tmp_lbl=torch.from_numpy(np.array(tmp_lbl))\n",
    "        tmp_lbl=tmp_lbl.long()\n",
    "        \n",
    "        \n",
    "        \n",
    "        return (tmp_img, tmp_lbl)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        # Compute total number of samples in the dataset and return\n",
    "        return len(self.lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset=MNIST_train(os.getcwd()+'/data/MNIST_cutsom_dataloader/Train/', os.getcwd()+'/data/MNIST_cutsom_dataloader/train_part.csv', apply_transform)\n",
    "\n",
    "val_dataset=MNIST_train(os.getcwd()+'/data/MNIST_cutsom_dataloader/Train/', os.getcwd()+'/data/MNIST_cutsom_dataloader/val_part.csv', apply_transform)\n",
    "\n",
    "test_dataset=MNIST_train(os.getcwd()+'/data/MNIST_cutsom_dataloader/Test/', os.getcwd()+'/data/MNIST_cutsom_dataloader/test.csv', apply_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(f, lbl) = train_dataset[0]\n",
    "print(f.shape)\n",
    "print(lbl)\n",
    "\n",
    "fig=plt.figure(figsize=(12, 12)) \n",
    "fig.add_subplot(2, 1, 1) \n",
    "f=f.numpy()\n",
    "f=np.squeeze(f)\n",
    "plt.imshow(f, cmap='gray', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=32, \n",
    "                                           shuffle=True, num_workers=2)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                          batch_size=32, shuffle=False, num_workers=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Defining the Network Model\n",
    "![title](lenet1.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Modified LeNet with Batch Norm Added\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "                                    nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, \n",
    "                                              stride=1, padding=0, dilation=1, groups=1, bias=False),\n",
    "                                    nn.BatchNorm2d(6)\n",
    "                                    )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "                                    nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, \n",
    "                                              stride=1, padding=0, dilation=1, groups=1, bias=False),\n",
    "                                    nn.BatchNorm2d(16)\n",
    "                                    )\n",
    "           \n",
    "            \n",
    "        self.fc1=nn.Sequential(\n",
    "                                    nn.Linear( in_features=16*5*5, out_features=120, bias=False),\n",
    "                                    nn.BatchNorm1d(120)\n",
    "                                    )\n",
    "        \n",
    "        self.fc2=nn.Sequential(\n",
    "                                    nn.Linear( in_features=120, out_features=84, bias=False),\n",
    "                                    nn.BatchNorm1d(84)\n",
    "                                    )\n",
    "                                    \n",
    "        \n",
    "       \n",
    "        self.fc3=nn.Linear( in_features=84, out_features=10, bias=True)\n",
    "                                    \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        \n",
    "        \n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Implement a CNN model of form: Conv+Maxpool->Conv+Maxpool with a variable \"depth\" number of blocks.\n",
    "# The number of Convolution filters are doubled after each block. \n",
    "# The feature dimensionality at the end of the Conv layers must be fixed, independent of the input image size\n",
    "\n",
    "### The Challenge is to write a code which generates the model in an iterative manner as depth is variable.\n",
    "### Global Avg Pooling ensures that the output feature dim is independent of input image size\n",
    "    # Other advantages: a) Low dimensionality of the FC layers   b) Explainability with CAM.\n",
    "\n",
    "\n",
    "#This concept is often employed for constructing CNN.\n",
    "#See for eg., DenseNet implementation: https://github.com/bamos/densenet.pytorch/blob/master/densenet.py line 99 onwards\n",
    "\n",
    "class my_Conv(nn.Module):\n",
    "    def __init__(self, inp_chnls, out_chnls):\n",
    "        super(my_Conv, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "                                    nn.Conv2d(in_channels=inp_chnls, out_channels=out_chnls, kernel_size=3, \n",
    "                                              stride=1, padding=1, dilation=1, groups=1, bias=False),\n",
    "                                    nn.BatchNorm2d(out_chnls),\n",
    "                                    nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "                                    )\n",
    "       \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class my_CNN(nn.Module):\n",
    "    def __init__(self, base_chnls, depth):\n",
    "        super(my_CNN, self).__init__()\n",
    "        \n",
    "        layer_list=[]\n",
    "        layer_list.append(my_Conv(1, base_chnls))\n",
    "        for i in range(0, depth-1):\n",
    "            layer_list.append(my_Conv(base_chnls, 2*base_chnls))\n",
    "            base_chnls=base_chnls*2\n",
    "            \n",
    "        self.layers=nn.Sequential(*layer_list)\n",
    "        \n",
    "        self.fc=nn.Linear( in_features=base_chnls, out_features=10, bias=True)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        ftr = self.layers(x)\n",
    "        ftr =  F.adaptive_avg_pool2d(ftr, (1,1))\n",
    "        ftr = ftr.view(ftr.size(0), -1)\n",
    "        out=self.fc(ftr)\n",
    "        return out   \n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Another way to code using ModuleList: see for example: \n",
    "# https://github.com/jvanvugt/pytorch-unet/blob/master/unet.py\n",
    "# line 48-53 , 66-67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model=LeNet() # 1. Simple CNN: LeNet\n",
    "\n",
    "model=my_CNN(base_chnls=2, depth=5)\n",
    "\n",
    "model=model.to(device) # Transfer the model from CPU to GPU\n",
    "print(model) # Print the model architecture\n",
    "\n",
    "\n",
    "\n",
    "# Count no of learnable parameters in the model\n",
    "def count_parameters(model):\n",
    "    # Returns only trainable params due to the last if\n",
    "    # wouldnot work for shared parameters which will be counted multiple times\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print( \"No. of learnable Network Parameters= \"+str(count_parameters(model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    correct = 0 # Correctly predicted \n",
    "    total = 0 # Total number of samples\n",
    "    running_loss=0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(val_loader):\n",
    "            \n",
    "            images = images.to(device) # put data into gpu\n",
    "            labels = labels.to(device)\n",
    "                    \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "            # torch.max returns  a tuple (max_value, max_idx), the mx_idx gives the class label \n",
    "            predicted = torch.max(outputs, 1)[1] \n",
    "    \n",
    "            # Compute Accuracy\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted.detach() == labels).sum().item()\n",
    "\n",
    "            running_loss=running_loss+loss.item() \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    acc=correct/total\n",
    "    model.train()\n",
    "    print (\"\\n Val_acc:  {:.4f}, Val_Classification Loss: {:.4f}\"\n",
    "                   .format(acc, running_loss/(i+1) ))\n",
    "            \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain an instance of loss and optimizer \n",
    "criterion = nn.CrossEntropyLoss() # This criterion combines nn.LogSoftmax() and nn.NLLLoss() in one single class\n",
    "\n",
    "init_lr=0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=init_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## TRAINING ###########\n",
    "# For updating learning rate\n",
    "def update_lr(optimizer, lr):    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "             \n",
    "        \n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader) # Number of batch updates in each epoch\n",
    "curr_lr = init_lr\n",
    "num_epochs=100 # maximum number of epochs for training\n",
    "\n",
    "ptnc_cnt=0 # for Early stopping\n",
    "patience=10 # Stop training if the val accuracy doesnot improve for \"patience\" epochs\n",
    "max_metric=0 # best val accuracy encountered so far\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    running_loss=0 # approximates the training loss by computing running average\n",
    "    model.train() # Certain layers (for eg., BatchNorm and Dropout have different behaviours during training and inference)\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device) # put data into gpu\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad() # # remove previous gradients\n",
    "        loss.backward() # backpropagation through automatic gradient computation\n",
    "        \n",
    "        optimizer.step() # Update the optimizer parameters\n",
    "        \n",
    "        \n",
    "        # Display Training Loss after every 25 batch of updates for current epoch\n",
    "        running_loss=running_loss+loss.item()\n",
    "        if (i+1) % 25 == 0:\n",
    "            print (\"Epoch [{}/{}], Batch [{}/{}] Train Loss: {:.4f}\"\n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, running_loss/(i+1)), end =\"\\r\")\n",
    "            \n",
    "            \n",
    "    ######### End of An Epoch ##################\n",
    "    \n",
    "    # Decay learning rate\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        curr_lr /= 10\n",
    "        update_lr(optimizer, curr_lr)\n",
    "        \n",
    "    # Monitor validation Loss\n",
    "    metric=validate(val_loader, model, criterion)\n",
    "    \n",
    "    # Checkpoint and Early Stopping \n",
    "    if metric>max_metric:\n",
    "        nm='best_wt_CNN.pt'\n",
    "        print(\"Val Performance improved, Saving checkpoint.. in \"+nm)\n",
    "        \n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict()\n",
    "            }, nm)\n",
    "        ptnc_cnt=0\n",
    "        max_metric=metric\n",
    "            \n",
    "    else:\n",
    "        ptnc_cnt=ptnc_cnt+1\n",
    "        print('Validation metric has not improved in last '+str(ptnc_cnt)+' batch updates')\n",
    "        if ptnc_cnt==patience:\n",
    "            print(\"Early Stopping !\")\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Training is complete, now load the best training weight from the checkpoint\n",
    "checkpoint = torch.load(nm)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "del checkpoint\n",
    "\n",
    "metric=validate(test_loader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
